# Dataset Download Tool

A flexible tool to download HuggingFace datasets (Sangraha & IndicCorp V2) to local storage and/or AWS S3 with comprehensive timing tracking.

## ğŸ“‹ Features

âœ… **Multiple Storage Modes**: Download to local, S3, or both  
âœ… **Test & Full Modes**: Test with limited data or download complete datasets  
âœ… **Runtime Configuration**: Override settings via command-line arguments  
âœ… **Comprehensive Timing**: Track time for each step and total execution  
âœ… **Progress Tracking**: Real-time progress with record counts  
âœ… **Error Handling**: Graceful error handling with detailed logging  
âœ… **Flexible Configuration**: YAML-based configuration with CLI overrides

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Basic Usage

```bash
# Download test data locally
python download.py --storage local --mode test

# Upload to S3
python download.py --storage s3 --s3-bucket YOUR-BUCKET --mode test

# Download locally AND upload to S3
python download.py --storage both --s3-bucket YOUR-BUCKET --mode test
```

## ğŸ“š Datasets

This tool downloads two high-quality Indic language datasets:

### 1. **Sangraha** - AI4Bharat Synthetic Dataset
- **Languages**: Hindi (Devanagari), Hindi (Latin), Tamil
- **Test Mode**: 10,000 rows per language (30,000 total)
- **Full Mode**: Complete dataset (~50 GB)
- **Source**: [ai4bharat/sangraha](https://huggingface.co/datasets/ai4bharat/sangraha)

### 2. **IndicCorp V2** - Hindi Corpus
- **Language**: Hindi (Devanagari)
- **Test Mode**: 50,000 rows
- **Full Mode**: Complete dataset (~200 GB)
- **Source**: [ai4bharat/IndicCorpV2](https://huggingface.co/datasets/ai4bharat/IndicCorpV2)

## ğŸ¯ Command-Line Options

### Available Arguments

| Argument | Description | Example |
|----------|-------------|---------|
| `--storage` | Storage mode: `local`, `s3`, or `both` | `--storage both` |
| `--s3-bucket` | S3 bucket name | `--s3-bucket my-bucket` |
| `--region` | AWS region | `--region us-east-1` |
| `--mode` | Download mode: `test` or `full` | `--mode full` |
| `--config` | Config file path | `--config custom.yml` |

### Usage Examples

#### Test Mode Examples

```bash
# Test data locally only
python download.py --storage local --mode test

# Test data to S3 only
python download.py --storage s3 --s3-bucket ai4bharat-data --mode test

# Test data to both local and S3
python download.py --storage both --s3-bucket ai4bharat-data --mode test
```

#### Full Mode Examples

```bash
# Full datasets locally (âš ï¸ ~250 GB)
python download.py --storage local --mode full

# Full datasets to S3 (recommended)
python download.py --storage s3 --s3-bucket ai4bharat-data --mode full

# Full datasets to both (âš ï¸ requires lots of disk space)
python download.py --storage both --s3-bucket ai4bharat-data --mode full
```

#### Advanced Examples

```bash
# Custom region
python download.py --storage s3 --s3-bucket my-bucket --region us-west-2 --mode test

# Use custom config file
python download.py --config prod-config.yml --mode full

# See all options
python download.py --help
```

## ğŸ“ Output Structure

### Local Storage

```
./data/downloaded_datasets/
â”œâ”€â”€ sangraha/
â”‚   â”œâ”€â”€ hin_Deva/
â”‚   â”‚   â”œâ”€â”€ part-00000.jsonl
â”‚   â”‚   â””â”€â”€ part-00001.jsonl
â”‚   â”œâ”€â”€ hin_Latn/
â”‚   â”‚   â”œâ”€â”€ part-00000.jsonl
â”‚   â”‚   â””â”€â”€ part-00001.jsonl
â”‚   â””â”€â”€ tam_Taml/
â”‚       â”œâ”€â”€ part-00000.jsonl
â”‚       â””â”€â”€ part-00001.jsonl
â””â”€â”€ indiccorp_v2/
    â””â”€â”€ hin/
        â”œâ”€â”€ part-00000.jsonl
        â”œâ”€â”€ part-00001.jsonl
        â”œâ”€â”€ part-00002.jsonl
        â”œâ”€â”€ part-00003.jsonl
        â”œâ”€â”€ part-00004.jsonl
        â””â”€â”€ part-00005.jsonl
```

### S3 Storage

```
s3://YOUR-BUCKET/
â””â”€â”€ hf/
    â”œâ”€â”€ sangraha/
    â”‚   â”œâ”€â”€ hin_Deva/
    â”‚   â”œâ”€â”€ hin_Latn/
    â”‚   â””â”€â”€ tam_Taml/
    â””â”€â”€ indiccorp_v2/
        â””â”€â”€ hin/
```

## âš™ï¸ Configuration

### config.yml

```yaml
# Storage configuration
storage:
  mode: local       # local | s3 | both
  local_dir: ./data/downloaded_datasets
  
aws:
  region: us-east-1
  s3_bucket: my-llm-datasets
  s3_prefix: hf

# Mode: 'test' applies limits below, 'full' downloads entire datasets
mode: test        # test | full

datasets:
  sangraha:
    repo: ai4bharat/sangraha
    subset: synthetic
    languages:
      - hin_Deva
      - hin_Latn
      - tam_Taml
    test_limit:
      type: rows
      value: 10000

  indiccorp_v2:
    repo: ai4bharat/IndicCorpV2
    name: indiccorp_v2
    split: hin_Deva
    test_limit:
      type: rows
      value: 50000
```

**Note**: Command-line arguments override config.yml values.

## ğŸ”§ AWS Setup

### 1. Configure AWS Credentials

```bash
aws configure
```

Enter:
- AWS Access Key ID
- AWS Secret Access Key
- Default region (e.g., `us-east-1`)
- Default output format (`json`)

### 2. Create S3 Bucket (if needed)

```bash
aws s3 mb s3://YOUR-BUCKET-NAME --region us-east-1
```

### 3. Verify Access

```bash
aws s3 ls s3://YOUR-BUCKET-NAME/
```

## ğŸ“Š Expected Output

```
============================================================
ğŸš€ Dataset Download Tool
============================================================
ğŸ”§ Using storage mode from command line: local
ğŸ”§ Using download mode from command line: test

âš™ï¸  Mode: test
ğŸ’¾ Storage: local
ğŸ“ Local dir: ./data/downloaded_datasets

============================================================
ğŸš€ Processing: sangraha
============================================================
  ğŸ“¥ Loading Sangraha dataset...
  ğŸŒ Language: hin_Deva
  ğŸ’¾ Saved: ./data/downloaded_datasets\sangraha/hin_Deva\part-00000.jsonl
  ğŸ“Š Progress: 10,000 records
  âœ… hin_Deva: 10,000 records, 2 shards
  ğŸŒ Language: hin_Latn
  ğŸ’¾ Saved: ./data/downloaded_datasets\sangraha/hin_Latn\part-00000.jsonl
  âœ… hin_Latn: 10,000 records, 2 shards
  ğŸŒ Language: tam_Taml
  ğŸ’¾ Saved: ./data/downloaded_datasets\sangraha/tam_Taml\part-00000.jsonl
  âœ… tam_Taml: 10,000 records, 2 shards
â±ï¸  Time: 59.02s

============================================================
ğŸš€ Processing: indiccorp_v2
============================================================
  ğŸ“¥ Loading IndicCorp V2 (split: hin_Deva)...
  ğŸ’¾ Saved: ./data/downloaded_datasets\indiccorp_v2/hin\part-00000.jsonl
  ğŸ“Š Progress: 10,000 records
  ğŸ’¾ Saved: ./data/downloaded_datasets\indiccorp_v2/hin\part-00001.jsonl
  ğŸ“Š Progress: 20,000 records
  âœ… Total: 50,000 records, 6 shards
â±ï¸  Time: 7.66s

============================================================
ğŸ“Š SUMMARY
============================================================
âœ… sangraha: 59.02s
âœ… indiccorp_v2: 7.66s

â±ï¸  TOTAL TIME: 66.68s
============================================================
ğŸ‰ Done!
```

## ğŸ’¡ Recommended Workflows

### Workflow 1: Test First, Then Full

```bash
# 1. Test with small data locally
python download.py --storage local --mode test

# 2. Verify data
dir .\data\downloaded_datasets

# 3. Upload test data to S3
aws s3 sync .\data\downloaded_datasets s3://YOUR-BUCKET/Testing/

# 4. Download full datasets to S3 (when ready)
python download.py --storage s3 --s3-bucket YOUR-BUCKET --mode full
```

### Workflow 2: Direct to S3

```bash
# Download full datasets directly to S3 (no local storage needed)
python download.py --storage s3 --s3-bucket YOUR-BUCKET --mode full
```

### Workflow 3: Local Backup + S3

```bash
# Download and backup to both local and S3
python download.py --storage both --s3-bucket YOUR-BUCKET --mode full
```

## ğŸ“ˆ Data Sizes

### Test Mode
- **Sangraha**: ~5 MB (30,000 records)
- **IndicCorp V2**: ~10 MB (50,000 records)
- **Total**: ~15 MB
- **Time**: ~1-2 minutes

### Full Mode
- **Sangraha**: ~50 GB (all languages, complete dataset)
- **IndicCorp V2**: ~200 GB (Hindi complete corpus)
- **Total**: ~250 GB
- **Time**: Several hours (depends on internet speed)

## ğŸ› Troubleshooting

### Error: "Unable to locate credentials"
```bash
# Configure AWS credentials
aws configure
```

### Error: "Invalid bucket name"
- Bucket names cannot contain slashes or special characters
- Use only lowercase letters, numbers, hyphens, and dots
- Example: `my-bucket-name` âœ…, `my-bucket/path` âŒ

### Error: "Access Denied"
- Check IAM permissions for S3 access
- Ensure bucket policy allows PutObject

### Slow Downloads
- Use `--storage s3` to skip local storage
- Check internet connection
- Consider running on AWS EC2 for faster S3 uploads

## ğŸ“ Additional Resources

- **AWS S3 Guide**: See `AWS_S3_GUIDE.md` for detailed AWS setup
- **HuggingFace Datasets**: https://huggingface.co/docs/datasets/
- **Sangraha Dataset**: https://huggingface.co/datasets/ai4bharat/sangraha
- **IndicCorp V2**: https://huggingface.co/datasets/ai4bharat/IndicCorpV2

## ğŸ†˜ Support

For issues or questions:
1. Check the troubleshooting section above
2. Review `AWS_S3_GUIDE.md` for AWS-specific issues
3. Verify your config.yml is properly formatted
4. Check AWS credentials and permissions

## ğŸ“„ License

MIT License - Feel free to use and modify as needed.
